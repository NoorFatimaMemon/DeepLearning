{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoorFatimaMemon/DeepLearning/blob/main/26_Intro_to_Autoencoders%20/26_Intro_to_Autoencoders_with_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoDZ-mITe28G"
      },
      "source": [
        "# **Autoencoders with Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable      # wraps tensors for autograd\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "hONUfiRnkeWv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aid9saa7ILqV",
        "outputId": "1febe0f1-b01b-4f6f-e191-295e832f7b61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./mlp_img'):\n",
        "    os.mkdir('./mlp_img')"
      ],
      "metadata": {
        "id": "zSMY9p7plSpL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Conversion Function\n",
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)           # Rescale from [-1, 1] to [0, 1]\n",
        "    x = x.clamp(0, 1)           # Clamp values to ensure they’re within [0,1]\n",
        "    x = x.view(x.size(0), 1, 28, 28)  # Reshape to image format (batch, channel, height, width)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_GuuGcuwpT0T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters and Dataset Setup\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "# Transforms images to tensors and normalizes pixel values from [0, 1] to [-1, 1].\n",
        "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])"
      ],
      "metadata": {
        "id": "cEGwa7wdq3g6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST('./data', transform=img_transform, download = True)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ySans4IKsyA",
        "outputId": "f0fb780a-0402-46a0-d284-a320756f43f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 340kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.17MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(True), nn.Linear(128, 64), nn.ReLU(True),\n",
        "                                     nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
        "\n",
        "        self.decoder = nn.Sequential(nn.Linear(3, 12), nn.ReLU(True), nn.Linear(12, 64), nn.ReLU(True),\n",
        "                                     nn.Linear(64, 128), nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8uP75Qc6K0et"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Setup**\n"
      ],
      "metadata": {
        "id": "ySjP03-mSzjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = autoencoder().cuda()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "eVrnCVHdxeCR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for data in dataloader:\n",
        "        img, _ = data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        img = Variable(img).cuda()\n",
        "        # ===================forward=====================\n",
        "        output = model(img)\n",
        "        loss = criterion(output, img)\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss:{:.4f}'\n",
        "          .format(epoch + 1, num_epochs, loss.data))\n",
        "    if epoch % 10 == 0:\n",
        "        pic = to_img(output.cpu().data)\n",
        "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obQKDih0i52T",
        "outputId": "1f8df50e-89f7-49e9-ad40-51faeb3f0dd8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/100], loss:0.1959\n",
            "epoch [2/100], loss:0.1655\n",
            "epoch [3/100], loss:0.1581\n",
            "epoch [4/100], loss:0.1657\n",
            "epoch [5/100], loss:0.1649\n",
            "epoch [6/100], loss:0.1398\n",
            "epoch [7/100], loss:0.1412\n",
            "epoch [8/100], loss:0.1482\n",
            "epoch [9/100], loss:0.1543\n",
            "epoch [10/100], loss:0.1397\n",
            "epoch [11/100], loss:0.1370\n",
            "epoch [12/100], loss:0.1360\n",
            "epoch [13/100], loss:0.1359\n",
            "epoch [14/100], loss:0.1287\n",
            "epoch [15/100], loss:0.1346\n",
            "epoch [16/100], loss:0.1384\n",
            "epoch [17/100], loss:0.1342\n",
            "epoch [18/100], loss:0.1295\n",
            "epoch [19/100], loss:0.1362\n",
            "epoch [20/100], loss:0.1313\n",
            "epoch [21/100], loss:0.1402\n",
            "epoch [22/100], loss:0.1330\n",
            "epoch [23/100], loss:0.1236\n",
            "epoch [24/100], loss:0.1255\n",
            "epoch [25/100], loss:0.1243\n",
            "epoch [26/100], loss:0.1396\n",
            "epoch [27/100], loss:0.1365\n",
            "epoch [28/100], loss:0.1322\n",
            "epoch [29/100], loss:0.1346\n",
            "epoch [30/100], loss:0.1226\n",
            "epoch [31/100], loss:0.1272\n",
            "epoch [32/100], loss:0.1330\n",
            "epoch [33/100], loss:0.1313\n",
            "epoch [34/100], loss:0.1272\n",
            "epoch [35/100], loss:0.1363\n",
            "epoch [36/100], loss:0.1389\n",
            "epoch [37/100], loss:0.1346\n",
            "epoch [38/100], loss:0.1240\n",
            "epoch [39/100], loss:0.1206\n",
            "epoch [40/100], loss:0.1173\n",
            "epoch [41/100], loss:0.1185\n",
            "epoch [42/100], loss:0.1218\n",
            "epoch [43/100], loss:0.1231\n",
            "epoch [44/100], loss:0.1210\n",
            "epoch [45/100], loss:0.1236\n",
            "epoch [46/100], loss:0.1205\n",
            "epoch [47/100], loss:0.1136\n",
            "epoch [48/100], loss:0.1199\n",
            "epoch [49/100], loss:0.1217\n",
            "epoch [50/100], loss:0.1160\n",
            "epoch [51/100], loss:0.1203\n",
            "epoch [52/100], loss:0.1275\n",
            "epoch [53/100], loss:0.1193\n",
            "epoch [54/100], loss:0.1156\n",
            "epoch [55/100], loss:0.1128\n",
            "epoch [56/100], loss:0.1247\n",
            "epoch [57/100], loss:0.1176\n",
            "epoch [58/100], loss:0.1185\n",
            "epoch [59/100], loss:0.1218\n",
            "epoch [60/100], loss:0.1278\n",
            "epoch [61/100], loss:0.1145\n",
            "epoch [62/100], loss:0.1190\n",
            "epoch [63/100], loss:0.1268\n",
            "epoch [64/100], loss:0.1196\n",
            "epoch [65/100], loss:0.1252\n",
            "epoch [66/100], loss:0.1274\n",
            "epoch [67/100], loss:0.1302\n",
            "epoch [68/100], loss:0.1381\n",
            "epoch [69/100], loss:0.1285\n",
            "epoch [70/100], loss:0.1245\n",
            "epoch [71/100], loss:0.1198\n",
            "epoch [72/100], loss:0.1182\n",
            "epoch [73/100], loss:0.1126\n",
            "epoch [74/100], loss:0.1097\n",
            "epoch [75/100], loss:0.1037\n",
            "epoch [76/100], loss:0.1159\n",
            "epoch [77/100], loss:0.1169\n",
            "epoch [78/100], loss:0.1201\n",
            "epoch [79/100], loss:0.1081\n",
            "epoch [80/100], loss:0.1121\n",
            "epoch [81/100], loss:0.1206\n",
            "epoch [82/100], loss:0.1215\n",
            "epoch [83/100], loss:0.1166\n",
            "epoch [84/100], loss:0.1258\n",
            "epoch [85/100], loss:0.1106\n",
            "epoch [86/100], loss:0.1118\n",
            "epoch [87/100], loss:0.1119\n",
            "epoch [88/100], loss:0.1179\n",
            "epoch [89/100], loss:0.1281\n",
            "epoch [90/100], loss:0.1234\n",
            "epoch [91/100], loss:0.1160\n",
            "epoch [92/100], loss:0.1335\n",
            "epoch [93/100], loss:0.1216\n",
            "epoch [94/100], loss:0.1170\n",
            "epoch [95/100], loss:0.1235\n",
            "epoch [96/100], loss:0.1181\n",
            "epoch [97/100], loss:0.1132\n",
            "epoch [98/100], loss:0.1224\n",
            "epoch [99/100], loss:0.1218\n",
            "epoch [100/100], loss:0.1133\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPX6LLC1snHlWE6TWqv3g6i",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}