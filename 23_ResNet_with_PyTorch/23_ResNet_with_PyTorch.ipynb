{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ResNet (Residual Networks) with PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torchvision     # for computer vision tasks like datasets & transformations\n",
    "import torchvision.transforms as transforms     # for image preprocessing methods like normalization, resizing\n",
    "import torch.nn as nn       # for nn layers & loss functions\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Selection (GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transforms.Compose**: Chains several transformations.\n",
    "\n",
    "**transforms.ToTensor()**: Converts images to tensors.\n",
    "\n",
    "**transforms.Normalize((mean), (std))**: Normalizes the image tensor, here mean and std are both 0.5. For MNIST, the values are grayscale (single channel), so only one mean and std value is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# DataLoader wraps the dataset to load data in batches (of size 4 here), with shuffling for training data.\n",
    "# num_workers controls number of CPU workers (or processes) used to load data. \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Labels (for MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST has 10 classes (digits 0 to 9)\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training the ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noor\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Noor\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads ResNet-50 architecture without pretrained weights.\n",
    "resnet = models.resnet50(pretrained=False, progress=True)\n",
    "# Modify the first convolutional layer to accept 1 channel instead of 3\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()   # loss function for classification \n",
    "# to update model weights using Adam algorithm\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.939\n",
      "[1,  4000] loss: 0.958\n",
      "[1,  6000] loss: 1.138\n",
      "[1,  8000] loss: 1.139\n",
      "[1, 10000] loss: 1.228\n",
      "[1, 12000] loss: 0.515\n",
      "[1, 14000] loss: 0.481\n",
      "[2,  2000] loss: 0.430\n",
      "[2,  4000] loss: 0.314\n",
      "[2,  6000] loss: 0.407\n",
      "[2,  8000] loss: 0.259\n",
      "[2, 10000] loss: 0.279\n",
      "[2, 12000] loss: 0.262\n",
      "[2, 14000] loss: 0.258\n",
      "[3,  2000] loss: 0.222\n",
      "[3,  4000] loss: 0.188\n",
      "[3,  6000] loss: 0.182\n",
      "[3,  8000] loss: 0.199\n",
      "[3, 10000] loss: 0.214\n",
      "[3, 12000] loss: 0.183\n",
      "[3, 14000] loss: 0.146\n",
      "[4,  2000] loss: 0.164\n",
      "[4,  4000] loss: 0.148\n",
      "[4,  6000] loss: 0.131\n",
      "[4,  8000] loss: 0.134\n",
      "[4, 10000] loss: 0.123\n",
      "[4, 12000] loss: 0.132\n",
      "[4, 14000] loss: 0.162\n",
      "[5,  2000] loss: 0.105\n",
      "[5,  4000] loss: 0.105\n",
      "[5,  6000] loss: 0.140\n",
      "[5,  8000] loss: 0.118\n",
      "[5, 10000] loss: 0.102\n",
      "[5, 12000] loss: 0.100\n",
      "[5, 14000] loss: 0.115\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    # Fetches mini-batches of data (inputs and labels) from trainloader\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # Resets gradients before each forward-backward pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Updates model weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Image (Unnormalize and Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # Un-normalizes the image by reversing the normalization process\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfOklEQVR4nO3de1jUVf4H8DeIgBcYBANEILHcRfO6YMTaapuspD5p3lZbUzbdxzRQkd1VKS9t6oK5pZm32me9VJpF673UNVTMfRAVxU1RdFdTCsFLcglzIOb8/ijn1zmDDMMMzgHer+fheXp/5zvf+XAQ/fSdM+e4CCEEiIiIiDTg6uwCiIiIiO5iY0JERETaYGNCRERE2mBjQkRERNpgY0JERETaYGNCRERE2mBjQkRERNpgY0JERETaYGNCRERE2mBjQkRERNqot8Zk5cqV6NChAzw9PREVFYWjR4/W10sRERFRI+FSH3vlfPjhhxg/fjzWrFmDqKgoLFu2DGlpacjLy4O/v3+NzzWZTCgoKICXlxdcXFwcXRoRERHVAyEEysrKEBQUBFfXut/3qJfGJCoqCr1798aKFSsA/NBshISEYOrUqZg9e3aNz/3qq68QEhLi6JKIiIjoPsjPz0dwcHCdn+/mwFoAABUVFcjOzkZycrL5mKurK2JiYpCZmWlxvtFohNFoNOe7fdKMGTPg4eHh6PKIiIioHhiNRixduhReXl52XcfhjcmNGzdQVVWFgIAA6XhAQADOnTtncX5KSgr+8pe/WBz38PBgY0JERNTA2DsNw+mfyklOTkZJSYn5Kz8/39klERERkZM4/I5J27Zt0axZMxQVFUnHi4qKEBgYaHE+74wQERHRXQ6/Y+Lu7o6IiAikp6ebj5lMJqSnpyM6OtrRL0dERESNiMPvmABAUlIS4uLiEBkZiUcffRTLli1DeXk5nn/++fp4OSIiImok6qUxGT16NK5fv4558+ahsLAQPXv2xJ49eywmxNZVdZNlqeGZP39+jY/z59w48OfcNPDn3DRY+zk7Qr00JgCQkJCAhISE+ro8ERERNUJO/1QOERER0V1sTIiIiEgbbEyIiIhIG2xMiIiISBtsTIiIiEgbbEyIiIhIG2xMiIiISBtsTIiIiEgbbEyIiIhIG2xMiIiISBtsTIiIiEgbbEyIiIhIG2xMiIiISBtsTIiIiEgbbEyIiIhIG27OLoDuj0GDBkn5k08+sThn3LhxUn7//ffrtSYiIiIV75gQERGRNtiYEBERkTbYmBAREZE2OMekkerUqZOU169fL+Xi4mKL5xw+fLgeK6LaaNasmZQ7duwo5d/97ndSfvnll6W8cuVKKc+YMcOB1dH9Mm3aNCmHh4dL+YUXXqjx+a6ulv/POXHiRCmvXbu2jtUR1S/eMSEiIiJtsDEhIiIibbAxISIiIm1wjkkj4evrK+Xdu3fX+PiqVassrvHll186vC6qWfv27aWszi3405/+ZNP11LVoli5dKuUrV67YdD2qXsuWLaXcr1+/Gs+/du2alF1cXKSszhmZMGGClIUQNWaVyWSyOLZs2TIpX7hwQcqff/55jdck20VGRkp52LBhUlbnkPXs2VPK169fl/LgwYOlXFZWZmeFeuIdEyIiItIGGxMiIiLSBhsTIiIi0gbnmDRQPj4+Up45c6aUO3ToUOPz9+zZ4+CKqDrqehIDBw6UcmpqqpS7dOli1+u1adNGyvHx8VKeNWuWXddvKgwGg5SXL18u5dDQUCn/6le/krI6h8TaHJO2bdvWWI86/2vFihVSPnv2rJQ3bNhgcQ31NZKSkqTMOSbW9e7dW8rqnJFRo0ZJOSwsTMrVrS9Tk9OnT0tZXeeoseIdEyIiItIGGxMiIiLShs2NyaFDh/D0008jKCgILi4u2LZtm/S4EALz5s1Du3bt0KJFC8TExFh8LI2IiIioOjbPMSkvL0ePHj0wYcIEDB8+3OLx1157DcuXL8eGDRsQFhaGuXPnIjY2Frm5ufD09HRI0WT5Hre19S5Wr14t5U8//dThNREQGxsr5QULFkg5IiKixudXVVVJ+dy5c1JW1yFR56yovLy8pFzdHit5eXlSPnjwYI3XbIxGjhwpZXVujjqHxFYPPPCATecfOnRIykOHDpVyaWlpjc9X55wAlt+Duv8OAU888YSU586dK2V1DN3cav4n9ObNm1JW9ydS15tR/0f/1KlTUr5z506Nr9dY2NyYDBw48J5/GQohsGzZMsyZM8f8i/Tuu+8iICAA27Ztw5gxY+yrloiIiBo1h84xuXTpEgoLCxETE2M+ZjAYEBUVhczMzGqfYzQaUVpaKn0RERFR0+TQxqSwsBAAEBAQIB0PCAgwP6ZKSUmBwWAwf4WEhDiyJCIiImpAnL6OSXJysvR5+tLSUjYn1VCbvU2bNklZXRdBxXVLHENdR+APf/iDlNV1Sby9vW26/ssvvyzlJUuWSLl///5SHjBgQI31Pf3001KeNGmSxWsWFxdLuUePHlL++uuv711wA6WuU+LoOSUqdR2SdevWSXnRokVSVucaqWuQWLuz3LdvX4tj1vbXaQrUf1v++Mc/SnnKlClSbt68uZR37twpZfXnmJWVJWV1TsitW7dqX2wT5tA7JoGBgQCAoqIi6XhRUZH5MZWHhwe8vb2lLyIiImqaHNqYhIWFITAwEOnp6eZjpaWlyMrKQnR0tCNfioiIiBohm9/K+fbbb/Hf//7XnC9duoScnBz4+voiNDQUiYmJWLhwITp16mT+uHBQUBCeeeYZR9ZNREREjZDNjcnx48fx61//2pzvzg+Ji4vD+vXrMXPmTJSXl2PSpEkoLi7G448/jj179nANEzup74WqaxCo7x+rn4f/7LPP6qWuxk79c7tmzRopjxs3zqbrXbx4Ucrq3ILq9jj5qZ/ejQSAiooKKbdo0ULKQUFBVmuytr/OSy+9ZPUaDU2/fv2k7Og5JZcvX5ay+j9m6h4oqk6dOklZXb9G1blz59oX96OFCxfa/JyGRJ0rBViu39SuXTspb9++Xcrq76f6c9NtXRF17hQAlJSUOKES+9jcmDzxxBM1TqJycXHBq6++ildffdWuwoiIiKjp4V45REREpA02JkRERKQNp69jQrWj7uVhzSuvvCJlo9HowGoaL/V9afU96Xt97P1e1Dkp6vwNW6n7U7m7u9t1veq0atXK4dd0psjISItj77zzjl3XVOf2qHNKhg0bJmV1zyN17k/Lli1rfD11r52rV69Kubo9kFTHjx+XcmNb20idX6XOFwEs55RMnjxZyuocL93+3rS2DsvgwYMtnqOudXTp0iXHF+ZgvGNCRERE2mBjQkRERNpgY0JERETa4BwTTal7rjz44INSVj+yre7e/NNF8Kh61a39sHv3bimrexSp1H1m1Pf61fVk7DVnzhwpnzlzRsp+fn5Sbt++vc2v0dj+7KjzMwDLvWds9cYbb0hZ/bmo1D9ru3btkrL6+63ufaXutVPdXAJrrl+/LuWbN2/afA2dqfsDhYaGWpxz4cIFKb///vtSru85JT4+PlJW19N5+OGHpaz+nKOioqSszqupbi8edb+fhoB3TIiIiEgbbEyIiIhIG2xMiIiISBucY6KJLl26SFn9fL1Kfb84ISFByrrt4aCDrl27Snnv3r0W51ibU6K+B62+R/3xxx/XsbrqqesWqPV5eXlJuS7vJ6v7/WzevNnma+jszTfftDimzuGwRt0vaPHixTWen5aWJmV1/RlrXF3l/2fs0KGDlNWfmfr9qM8HgOnTp9tUQ0OTlZUlZXWtF8ByD6IDBw5IOTs7W8rW9jSyZsyYMTW+vq+vr5TLysqkrM4hUbPJZJLy888/b1HD+fPna1esRnjHhIiIiLTBxoSIiIi0wcaEiIiItME5Jk6i7nHy0UcfSVmdO6C+Z/y///1PyqdOnXJgdY2Duu/NJ598IuXa7HujrgswdOhQKf/73/+uY3XVc3OTfyVnzpwpZVv36lHduHHD4tjBgwelrL5v3dCoa4Ko78sDlusAWaPOGVFf41//+peU1bk+6p5Lb7/9tpRzc3OlHBYWJuWNGzdKOSkpScq3b9+WckP/GdaFuqbQI488YnHOwoULpayuCxIXF+fQmtT1pdauXSvlrVu3Sjk/P1/K6jy47t27S1md47Zjx4461akb3jEhIiIibbAxISIiIm2wMSEiIiJtsDEhIiIibXDyq5OMGjVKyuHh4VJWJ+epE7uee+65eqmrMZk4caKU27VrZ/U5JSUlUh45cqSU7Z3s2qdPHyk/9dRTUh40aJCUe/bsadfrqWbPnm1xrKCgwKGv4WxDhgyRcm1+7rZSFzicNm2alC9fvizlc+fO2XR9dRKmtU0HDQaDTddvCtS/MwHLhSidTd1gMj09XcrqopDqhyQa66J5vGNCRERE2mBjQkRERNpgY0JERETa4ByT+6R169ZSTkxMtOn57733npS//PJLOytq/KpbWMua+fPnS1ldfKxly5ZSVjdXUzftUue5+Pn5Sbkum+7ZQt3M8d13363X12sq1AXNqtsQ0h5z5syRsq0LwpGeevXqJWV1gTR1M1d1gbZJkyZJubS01IHV6YN3TIiIiEgbbEyIiIhIG2xMiIiISBucY3KfvPLKK1JW32u0Zs+ePQ6spmlQ53fU5n36cePGSVldd0Rdb6Zbt251rO4H6noYOTk5UlY3/UpNTZWyupmcasOGDVKuqqqyscKGx8XFpcaso759+0pZ3bTT1k35Ro8ebXHs4sWLthdGdpkyZYqUly5dKmV1M1d1naTBgwdLubHOKVHxjgkRERFpw6bGJCUlBb1794aXlxf8/f3xzDPPIC8vTzrnzp07iI+Ph5+fH1q3bo0RI0agqKjIoUUTERFR42RTY5KRkYH4+HgcOXIE+/btQ2VlJQYMGIDy8nLzOTNmzMDOnTuRlpaGjIwMFBQUYPjw4Q4vnIiIiBofm+aYqPMc1q9fD39/f2RnZ6Nv374oKSnBP/7xD2zatAlPPvkkAGDdunXo3Lkzjhw5gscee8xxlWtO3QNh8uTJNj1fnR/x6aef2l1TU3P27Fkpq/NDqhMREVFjttUHH3wg5Z07d0pZXafgypUrUh47dqyU/f39bXr9zZs323R+Y6DOJarLGiDqOkHquiX2GjhwoJTV9SzUOSXWvoeFCxdK+eOPP7ajOqor9e/5ZcuWSVldt2jevHlSXrJkiZSNRqPjimtA7JpjcnfDM19fXwBAdnY2KisrERMTYz4nPDwcoaGhFn8BExEREanq/Kkck8mExMRE9OnTx7wDYmFhIdzd3eHj4yOdGxAQgMLCwmqvYzQapa6wqcw6JiIiIkt1vmMSHx+P06dP232rOCUlBQaDwfwVEhJi1/WIiIio4arTHZOEhATs2rULhw4dQnBwsPl4YGAgKioqUFxcLN01KSoqQmBgYLXXSk5ORlJSkjmXlpY2iubk2rVrUra2DoG6p8knn3zi8JqaGnXtmNdff93ua2ZnZ0tZnTOizin57rvvbLp+q1atpPzSSy9J2dr+P4cOHZLy559/btPrNwbbt2+X8syZMy3OadeuXY3XsHftk4cffljKc+fOlXJsbKyUDQaDTdc/deqUlNX1buj+ePHFF6X8t7/9TcrqOiXqn4NFixZJmXsi/cCmOyZCCCQkJGDr1q3Yv38/wsLCpMcjIiLQvHlzpKenm4/l5eXhypUriI6OrvaaHh4e8Pb2lr6IiIioabLpjkl8fDw2bdqE7du3w8vLyzxvxGAwoEWLFjAYDJg4cSKSkpLg6+sLb29vTJ06FdHR0U3qEzlERERUNzY1JqtXrwYAPPHEE9LxdevW4fe//z2AH5bcdXV1xYgRI2A0GhEbG4tVq1Y5pFgiIiJq3GxqTGrz/penpydWrlyJlStX1rmohmjQoEFStrYOwenTp6Ws7qlw48YNB1bXNKWlpdWYdfSzn/1MyrVZe+Wndu3aJeWm+J61uhbMe++9Z3FOdfNOfkrdgyglJUXKd5dKuJepU6dK2d6fQ25urpSHDRsmZfV7pvoRHx8v5cWLF0vZ09NTyuoyGeqfo6b4+1kb3CuHiIiItMHGhIiIiLTBxoSIiIi0UeeVX5s6dR2EBQsW2PT8q1evSplL9hNguc6BNT/dQBMAPvvsM0eW0yioa8EAlitMq+tJqMaPH2/Ta7q6yv/PZ20dI2vP37hxo5Q5p+T+6Nixo5RTU1OlrM4pWb9+vZQTExOlXFVV5bDaGjPeMSEiIiJtsDEhIiIibbAxISIiIm1wjkkdxcTESLlHjx41nn/r1i0p79+/3+E1UcMTEREh5YEDB9r0fHXdEnUPFaqeuqeJup6EtTkn1lhbx8ia2bNnS9kR+zyRdeqebv/85z+lrO5lpa5jkpycXD+FNTG8Y0JERETaYGNCRERE2mBjQkRERNrgHJM6OnPmjJRv374tZfW9yC1btkh5yZIl9VMYNShdunSRsru7u03P55ySuvn++++lrM4VyMnJkfKcOXOk3L17dymrv+/WFBQUSPndd9+tsR6qH6GhoVLevn27lNW5g0eOHJEyf071g3dMiIiISBtsTIiIiEgbbEyIiIhIG5xjUkcnTpyQsre3t5MqoYasW7dudj1fnZtAjrF3794a85AhQ6SszlXo27evlHNzc6W8du1aKXPvG+dIT0+X8kMPPSTljz76SMqTJ0+WcnFxcb3U1dTxjgkRERFpg40JERERaYONCREREWmDjQkRERFpg5NfiZxo5syZNWbS044dO2p8fMWKFfepEnIkdbLrCy+8IOWSkpL7WU6TxTsmREREpA02JkRERKQNNiZERESkDc4xISKiJqlTp07OLoGqwTsmREREpA02JkRERKQNNiZERESkDTYmREREpA02JkRERKQNmxqT1atXo3v37vD29oa3tzeio6Oxe/du8+N37txBfHw8/Pz80Lp1a4wYMQJFRUUOL5qIiIgaJ5sak+DgYKSmpiI7OxvHjx/Hk08+iaFDh+LMmTMAgBkzZmDnzp1IS0tDRkYGCgoKMHz48HopnIiIiBofFyGEsOcCvr6+WLJkCUaOHIkHHngAmzZtwsiRIwEA586dQ+fOnZGZmYnHHnusVtcrLS2FwWDA7Nmz4eHhYU9pREREdJ8YjUakpqaipKQE3t7edb5OneeYVFVVYfPmzSgvL0d0dDSys7NRWVmJmJgY8znh4eEIDQ1FZmbmPa9jNBpRWloqfREREVHTZHNj8sUXX6B169bw8PDA5MmTsXXrVnTp0gWFhYVwd3eHj4+PdH5AQAAKCwvveb2UlBQYDAbzV0hIiM3fBBERETUONjcmP//5z5GTk4OsrCxMmTIFcXFxyM3NrXMBycnJKCkpMX/l5+fX+VpERETUsNm8V467uzsefvhhAEBERASOHTuGN998E6NHj0ZFRQWKi4uluyZFRUUIDAy85/U8PDw4l4SIiIgAOGAdE5PJBKPRiIiICDRv3hzp6enmx/Ly8nDlyhVER0fb+zJERETUBNh0xyQ5ORkDBw5EaGgoysrKsGnTJhw8eBB79+6FwWDAxIkTkZSUBF9fX3h7e2Pq1KmIjo6u9SdyiIiIqGmzqTG5du0axo8fj6tXr8JgMKB79+7Yu3cvfvOb3wAAli5dCldXV4wYMQJGoxGxsbFYtWqVTQXd/fSy0Wi06XlERETkPHf/3bZzFRL71zFxtK+++oqfzCEiImqg8vPzERwcXOfna9eYmEwmFBQUQAiB0NBQ5Ofn27VQS1NXWlqKkJAQjqMdOIb24xg6BsfRfhxD+91rDIUQKCsrQ1BQEFxd6z6F1eZP5dQ3V1dXBAcHmxdau7svD9mH42g/jqH9OIaOwXG0H8fQftWNocFgsPu63F2YiIiItMHGhIiIiLShbWPi4eGB+fPnc/E1O3Ec7ccxtB/H0DE4jvbjGNqvvsdQu8mvRERE1HRpe8eEiIiImh42JkRERKQNNiZERESkDTYmREREpA1tG5OVK1eiQ4cO8PT0RFRUFI4ePerskrSVkpKC3r17w8vLC/7+/njmmWeQl5cnnXPnzh3Ex8fDz88PrVu3xogRI1BUVOSkivWXmpoKFxcXJCYmmo9xDGvn66+/xnPPPQc/Pz+0aNEC3bp1w/Hjx82PCyEwb948tGvXDi1atEBMTAwuXLjgxIr1UlVVhblz5yIsLAwtWrTAQw89hAULFkj7j3AMZYcOHcLTTz+NoKAguLi4YNu2bdLjtRmvb775BmPHjoW3tzd8fHwwceJEfPvtt/fxu3C+msaxsrISs2bNQrdu3dCqVSsEBQVh/PjxKCgokK7hiHHUsjH58MMPkZSUhPnz5+PEiRPo0aMHYmNjce3aNWeXpqWMjAzEx8fjyJEj2LdvHyorKzFgwACUl5ebz5kxYwZ27tyJtLQ0ZGRkoKCgAMOHD3di1fo6duwY3n77bXTv3l06zjG07tatW+jTpw+aN2+O3bt3Izc3F6+//jratGljPue1117D8uXLsWbNGmRlZaFVq1aIjY3FnTt3nFi5PhYvXozVq1djxYoVOHv2LBYvXozXXnsNb731lvkcjqGsvLwcPXr0wMqVK6t9vDbjNXbsWJw5cwb79u3Drl27cOjQIUyaNOl+fQtaqGkcb9++jRMnTmDu3Lk4ceIEtmzZgry8PAwZMkQ6zyHjKDT06KOPivj4eHOuqqoSQUFBIiUlxYlVNRzXrl0TAERGRoYQQoji4mLRvHlzkZaWZj7n7NmzAoDIzMx0VplaKisrE506dRL79u0T/fr1E9OnTxdCcAxra9asWeLxxx+/5+Mmk0kEBgaKJUuWmI8VFxcLDw8P8cEHH9yPErU3ePBgMWHCBOnY8OHDxdixY4UQHENrAIitW7eac23GKzc3VwAQx44dM5+ze/du4eLiIr7++uv7VrtO1HGsztGjRwUAcfnyZSGE48ZRuzsmFRUVyM7ORkxMjPmYq6srYmJikJmZ6cTKGo6SkhIAgK+vLwAgOzsblZWV0piGh4cjNDSUY6qIj4/H4MGDpbECOIa1tWPHDkRGRmLUqFHw9/dHr1698Pe//938+KVLl1BYWCiNo8FgQFRUFMfxR7/85S+Rnp6O8+fPAwBOnTqFw4cPY+DAgQA4hraqzXhlZmbCx8cHkZGR5nNiYmLg6uqKrKys+15zQ1FSUgIXFxf4+PgAcNw4areJ340bN1BVVYWAgADpeEBAAM6dO+ekqhoOk8mExMRE9OnTB127dgUAFBYWwt3d3fyH566AgAAUFhY6oUo9bd68GSdOnMCxY8csHuMY1s7FixexevVqJCUl4aWXXsKxY8cwbdo0uLu7Iy4uzjxW1f1+cxx/MHv2bJSWliI8PBzNmjVDVVUVFi1ahLFjxwIAx9BGtRmvwsJC+Pv7S4+7ubnB19eXY3oPd+7cwaxZs/Dss8+aN/Jz1Dhq15iQfeLj43H69GkcPnzY2aU0KPn5+Zg+fTr27dsHT09PZ5fTYJlMJkRGRuKvf/0rAKBXr144ffo01qxZg7i4OCdX1zB89NFH2LhxIzZt2oRHHnkEOTk5SExMRFBQEMeQtFBZWYnf/va3EEJg9erVDr++dm/ltG3bFs2aNbP4tENRURECAwOdVFXDkJCQgF27duHAgQMIDg42Hw8MDERFRQWKi4ul8zmm/y87OxvXrl3DL37xC7i5ucHNzQ0ZGRlYvnw53NzcEBAQwDGshXbt2qFLly7Ssc6dO+PKlSsAYB4r/n7f25///GfMnj0bY8aMQbdu3TBu3DjMmDEDKSkpADiGtqrNeAUGBlp8uOL777/HN998wzFV3G1KLl++jH379pnvlgCOG0ftGhN3d3dEREQgPT3dfMxkMiE9PR3R0dFOrExfQggkJCRg69at2L9/P8LCwqTHIyIi0Lx5c2lM8/LycOXKFY7pj/r3748vvvgCOTk55q/IyEiMHTvW/N8cQ+v69Olj8VH18+fP48EHHwQAhIWFITAwUBrH0tJSZGVlcRx/dPv2bbi6yn81N2vWDCaTCQDH0Fa1Ga/o6GgUFxcjOzvbfM7+/fthMpkQFRV132vW1d2m5MKFC/jss8/g5+cnPe6wcazDZN16t3nzZuHh4SHWr18vcnNzxaRJk4SPj48oLCx0dmlamjJlijAYDOLgwYPi6tWr5q/bt2+bz5k8ebIIDQ0V+/fvF8ePHxfR0dEiOjraiVXr76efyhGCY1gbR48eFW5ubmLRokXiwoULYuPGjaJly5bi/fffN5+TmpoqfHx8xPbt28V//vMfMXToUBEWFia+++47J1auj7i4ONG+fXuxa9cucenSJbFlyxbRtm1bMXPmTPM5HENZWVmZOHnypDh58qQAIN544w1x8uRJ86dFajNeTz31lOjVq5fIysoShw8fFp06dRLPPvuss74lp6hpHCsqKsSQIUNEcHCwyMnJkf6tMRqN5ms4Yhy1bEyEEOKtt94SoaGhwt3dXTz66KPiyJEjzi5JWwCq/Vq3bp35nO+++068+OKLok2bNqJly5Zi2LBh4urVq84rugFQGxOOYe3s3LlTdO3aVXh4eIjw8HDxzjvvSI+bTCYxd+5cERAQIDw8PET//v1FXl6ek6rVT2lpqZg+fboIDQ0Vnp6eomPHjuLll1+W/vLnGMoOHDhQ7d+BcXFxQojajdfNmzfFs88+K1q3bi28vb3F888/L8rKypzw3ThPTeN46dKle/5bc+DAAfM1HDGOLkL8ZDlBIiIiIifSbo4JERERNV1sTIiIiEgbbEyIiIhIG2xMiIiISBtsTIiIiEgbbEyIiIhIG2xMiIiISBtsTIiIiEgbbEyIiIhIG2xMiIiISBtsTIiIiEgbbEyIiIhIG/8HLKaCRxShnCsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels:           1     9     0     9\n",
      "Predicted labels:      1     9     0     9\n"
     ]
    }
   ],
   "source": [
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "# Perform a forward pass to get the model's predictions\n",
    "outputs = resnet(images)\n",
    "# Get the predicted labels by finding the index with the maximum score for each image\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "images = images.cpu()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('True labels:      ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "print('Predicted labels: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
